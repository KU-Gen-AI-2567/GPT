{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gpvcd-dWuZg"
      },
      "source": [
        "# GPT - 01418496\n",
        "**สมาชิกกลุ่ม**\n",
        "\n",
        "นายศิวกร ภาสว่าง 6410451423\n",
        "\n",
        "นางสาว เเพรวรุ้ง พุดชะวา 6410451253\n",
        "\n",
        "นางสาว มารีน่า มิทซุย 6410450222\n",
        "\n",
        "หมู่ 200\n",
        "\n",
        "ชุดข้อมูล : Disneyland Reviews\n",
        "\n",
        "ลิ้งดาวน์โหลด : https://www.kaggle.com/datasets/arushchillar/disneyland-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TJ99SV3bWuZh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import kagglehub\n",
        "import shutil\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrUf4zRWuZh"
      },
      "source": [
        "## Setting to execute on Processor (GPU or CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChVjtilkWuZi",
        "outputId": "060f6280-0f53-41ec-a154-250a2b0cea77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Execute on GPU\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices(\"GPU\")\n",
        "if len(gpus) > 0:\n",
        "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    print(\"Execute on GPU\")\n",
        "else:\n",
        "    print(\"Execute on CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij-RDzKpWuZi"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cso5wPROWuZi",
        "outputId": "94d16c26-4035-40a4-a9d9-1a09467a9a1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/arushchillar/disneyland-reviews/versions/1\n",
            "Download Dataset Complete\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset folder in latest version\n",
        "if not \"dataset\" in os.listdir(\".\"):\n",
        "    path = kagglehub.dataset_download(\"arushchillar/disneyland-reviews\")\n",
        "    print(\"Path to dataset files:\", path)\n",
        "    shutil.move(path, \"./dataset\")\n",
        "    print(\"Download Dataset Complete\")\n",
        "else:\n",
        "    print(\"Download Dataset Already\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KyZCEc7WuZi"
      },
      "source": [
        "## Prepossessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asz8mrRCWuZi",
        "outputId": "80739cfc-eeaf-4664-e635-9560ae81ec35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Review_ID  Rating Year_Month     Reviewer_Location  \\\n",
            "0  670772142       4     2019-4             Australia   \n",
            "1  670682799       4     2019-5           Philippines   \n",
            "2  670623270       4     2019-4  United Arab Emirates   \n",
            "3  670607911       4     2019-4             Australia   \n",
            "4  670607296       4     2019-4        United Kingdom   \n",
            "\n",
            "                                         Review_Text               Branch  \n",
            "0  If you've ever been to Disneyland anywhere you...  Disneyland_HongKong  \n",
            "1  Its been a while since d last time we visit HK...  Disneyland_HongKong  \n",
            "2  Thanks God it wasn   t too hot or too humid wh...  Disneyland_HongKong  \n",
            "3  HK Disneyland is a great compact park. Unfortu...  Disneyland_HongKong  \n",
            "4  the location is not in the city, took around 1...  Disneyland_HongKong  \n"
          ]
        }
      ],
      "source": [
        "file_path = \"./dataset/DisneylandReviews.csv\"\n",
        "df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2kpq-WJeIHs",
        "outputId": "6011d795-9b27-4969-d656-b9d83ad6c77f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      reviewer_location               branch  rating  \\\n",
            "0             Australia  Disneyland_HongKong       4   \n",
            "1           Philippines  Disneyland_HongKong       4   \n",
            "2  United Arab Emirates  Disneyland_HongKong       4   \n",
            "3             Australia  Disneyland_HongKong       4   \n",
            "4        United Kingdom  Disneyland_HongKong       4   \n",
            "\n",
            "                                         review_text  \n",
            "0  If you've ever been to Disneyland anywhere you...  \n",
            "1  Its been a while since d last time we visit HK...  \n",
            "2  Thanks God it wasn   t too hot or too humid wh...  \n",
            "3  HK Disneyland is a great compact park. Unfortu...  \n",
            "4  the location is not in the city, took around 1...  \n"
          ]
        }
      ],
      "source": [
        "df_selected = df[[\"Reviewer_Location\", \"Branch\", \"Rating\", \"Review_Text\"]]\n",
        "df_selected = df_selected.rename(columns=str.lower)\n",
        "print(df_selected.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TmtK_TIcGi8",
        "outputId": "a10243ab-a9d0-4bf9-91b4-4ea9a20accff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'reviewer_location': 'Australia',\n",
              " 'branch': 'Disneyland_HongKong',\n",
              " 'rating': 4,\n",
              " 'review_text': \"If you've ever been to Disneyland anywhere you'll find Disneyland Hong Kong very similar in the layout when you walk into main street! It has a very familiar feel. One of the rides  its a Small World  is absolutely fabulous and worth doing. The day we visited was fairly hot and relatively busy but the queues moved fairly well. \"}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_list = df_selected.to_dict(orient=\"records\")\n",
        "data_list[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZZAiU-dNvb"
      },
      "source": [
        "### Sequence construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fET05xSadTP8",
        "outputId": "be91cdf0-7677-421a-cf92-b213b26a2ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42656 recipes loaded\n",
            "Disneyland review : United States : Disneyland_HongKong : 5 : Disneyland never cease to amaze me! I've been to Disneyland florida and I thought I have exhausted the kid in me but nope! I still had so much fun in disneyland hong kong. 2 DL off my bucketlist and more to come!     \n"
          ]
        }
      ],
      "source": [
        "filtered_data = [\n",
        "    \"Disneyland review : \"\n",
        "    + x[\"reviewer_location\"]\n",
        "    + \" : \"\n",
        "    + x[\"branch\"]\n",
        "    + \" : \"\n",
        "    + str(x[\"rating\"])\n",
        "    + \" : \"\n",
        "    + x[\"review_text\"]\n",
        "\n",
        "    for x in data_list\n",
        "    if x[\"reviewer_location\"] is not None\n",
        "    and x[\"branch\"] is not None\n",
        "    and x[\"rating\"] is not None\n",
        "    and x[\"review_text\"] is not None\n",
        "]\n",
        "\n",
        "n_data = len(filtered_data)\n",
        "print(f\"{n_data} recipes loaded\")\n",
        "\n",
        "example = filtered_data[10]\n",
        "print(example)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjC6LOBohl6q"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8ObIm4LRhj3T",
        "outputId": "e29cd856-bd5c-49e3-ab96-5111da2c2b5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Disneyland review : United States : Disneyland_HongKong : 5 : Disneyland never cease to amaze me ! I've been to Disneyland florida and I thought I have exhausted the kid in me but nope ! I still had so much fun in disneyland hong kong . 2 DL off my bucketlist and more to come ! \""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def pad_punctuation(s):\n",
        "    s = re.sub(r\"([^\\w\\s'-])\", r\" \\1 \", s) # ไม่แยก _ , -\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in filtered_data]\n",
        "\n",
        "example_data = text_data[10]\n",
        "example_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0UxOi-jtiK",
        "outputId": "779c56df-3094-4c0e-97da-e28411e5f768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: \n",
            "1: [UNK]\n",
            "2: .\n",
            "3: the\n",
            "4: :\n",
            "5: and\n",
            "6: ,\n",
            "7: to\n",
            "8: a\n",
            "9: of\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "BATCH_SIZE = 32 # 🤔\n",
        "VOCAB_SIZE = 10000 # 🤔\n",
        "MAX_LEN = 80 # 🤔\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(text_data)\n",
        "text_ds = text_ds.batch(BATCH_SIZE)\n",
        "text_ds = text_ds.shuffle(1000)\n",
        "\n",
        "\n",
        "vectorize_layer = layers.TextVectorization( # 🤔\n",
        "    standardize=\"lower\", # 🤔\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")\n",
        "\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "\n",
        "for i, word in enumerate(vocab[:10]):\n",
        "    print(f\"{i}: {word}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpoG-W8Uk8L3",
        "outputId": "12a02fe6-a45a-41df-b22c-4621d8bec0cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  14   22    4   45   64    4  104    4   39    4   14  195    1    7\n",
            " 4191  158   19  426   91    7   14  246    5   17  349   17   34 1631\n",
            "    3  431   11  158   21 4345   19   17  125   44   35   89   98   11\n",
            "   14  234  235    2   80 1006  205   42    1    5   68    7  221   19\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "example_tokenised = vectorize_layer(example_data)\n",
        "print(example_tokenised.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfTCL9Bhk-9u"
      },
      "source": [
        "### Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAEmiBW4lC8v",
        "outputId": "036b7110-ec01-430f-fd00-6de7fbc8bbdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(80,), dtype=int64, numpy=\n",
              "array([  14,   22,    4,   45,   64,    4,   54,    4,   39,    4,  170,\n",
              "         96,   17, 2101,   28,    8,  333,    6,   47,   34, 1159,   35,\n",
              "        109,  196,  225,  283,   17,   12,   33,   28,    8,  333,    5,\n",
              "        202,  262,    7,  126,   42,   69,   33,   12,  167,    2,   17,\n",
              "        211,   84,    8,   58,   72,    7,  417,    8,   30,  728,    6,\n",
              "         29,   57,    3,  155,  100,   18,   56,   63,    5,   85,    8,\n",
              "        156,   68,  105,   29,  151,  332,    2,  147,   11,  905,   16,\n",
              "          8,  151,  802])>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)\n",
        "example_input_output = train_ds.take(1).get_single_element()\n",
        "\n",
        "example_input_output[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QjmJ4trlFSX",
        "outputId": "0c634f35-1bc6-4e3a-d63d-4a25442bc73d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(80,), dtype=int64, numpy=\n",
              "array([  22,    4,   45,   64,    4,   54,    4,   39,    4,  170,   96,\n",
              "         17, 2101,   28,    8,  333,    6,   47,   34, 1159,   35,  109,\n",
              "        196,  225,  283,   17,   12,   33,   28,    8,  333,    5,  202,\n",
              "        262,    7,  126,   42,   69,   33,   12,  167,    2,   17,  211,\n",
              "         84,    8,   58,   72,    7,  417,    8,   30,  728,    6,   29,\n",
              "         57,    3,  155,  100,   18,   56,   63,    5,   85,    8,  156,\n",
              "         68,  105,   29,  151,  332,    2,  147,   11,  905,   16,    8,\n",
              "        151,  802,   29])>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_input_output[1][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsqF56p7qm3b"
      },
      "source": [
        "### Casual masking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6HcZz0wqvA2",
        "outputId": "dcab214b-37de-4ee3-c162-23d9b205efd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
        "    i = tf.range(n_dest)[:, None]\n",
        "    j = tf.range(n_src)\n",
        "    m = i >= j - n_src + n_dest\n",
        "    mask = tf.cast(m, dtype)\n",
        "    mask = tf.reshape(mask, [1, n_dest, n_src])\n",
        "    mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0)\n",
        "    return tf.tile(mask, mult)\n",
        "\n",
        "np.transpose(causal_attention_mask(1, 10, 10, dtype=tf.int32)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrkeTsXEWuZi"
      },
      "source": [
        "## Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYPvDmZEWuZi"
      },
      "outputs": [],
      "source": [
        "# code to create model\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.key_dim = key_dim\n",
        "        self.embed_dim = embed_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.attn = layers.MultiHeadAttention(num_heads, key_dim, output_shape=embed_dim)\n",
        "        self.dropout_1 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.ffn_1 = layers.Dense(self.ff_dim, activation=\"relu\")\n",
        "        self.ffn_2 = layers.Dense(self.embed_dim)\n",
        "        self.dropout_2 = layers.Dropout(self.dropout_rate)\n",
        "        self.ln_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size = input_shape[0]\n",
        "        seq_len = input_shape[1]\n",
        "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
        "        attention_output, attention_scores = self.attn(inputs, inputs, attention_mask=causal_mask, return_attention_scores=True)\n",
        "        attention_output = self.dropout_1(attention_output)\n",
        "        out1 = self.ln_1(inputs + attention_output)\n",
        "        ffn_1 = self.ffn_1(out1)\n",
        "        ffn_2 = self.ffn_2(ffn_1)\n",
        "        ffn_output = self.dropout_2(ffn_2)\n",
        "        return (self.ln_2(out1 + ffn_output), attention_scores)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"key_dim\": self.key_dim,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "                \"num_heads\": self.num_heads,\n",
        "                \"ff_dim\": self.ff_dim,\n",
        "                \"dropout_rate\": self.dropout_rate,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, max_len, vocab_size, embed_dim):\n",
        "        super(TokenAndPositionEmbedding, self).__init__()\n",
        "        self.max_len = max_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim) # GPT-style\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = tf.shape(x)[-1]\n",
        "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"max_len\": self.max_len,\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"embed_dim\": self.embed_dim,\n",
        "            }\n",
        "        )\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import models, losses\n",
        "\n",
        "EMBEDDING_DIM = 256 # 🤔\n",
        "KEY_DIM = 256 # 🤔\n",
        "N_HEADS = 2 # 🤔\n",
        "FEED_FORWARD_DIM = 256 # 🤔\n",
        "\n",
        "inputs = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
        "gpt = models.Model(inputs=inputs, outputs=[outputs, attention_scores])\n",
        "gpt.compile(\"adam\", loss=[losses.SparseCategoricalCrossentropy(), None])\n",
        "gpt.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import callbacks\n",
        "\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.word_to_index = {word: index for index, word in enumerate(index_to_word)}\n",
        "\n",
        "    def sample_from(self, probs, temperature):\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs # weighted random\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [self.word_to_index.get(x, 1) for x in start_prompt.split()]\n",
        "        sample_token = None\n",
        "        info = []\n",
        "\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
        "            x = np.array([start_tokens])\n",
        "            y, att = self.model.predict(x, verbose=0)\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
        "            info.append(\n",
        "                {\n",
        "                    \"prompt\": start_prompt,\n",
        "                    \"word_probs\": probs,\n",
        "                    \"atts\": att[0, :, -1, :],\n",
        "                }\n",
        "            )\n",
        "\n",
        "            start_tokens.append(sample_token)\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "\n",
        "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.generate(\"wine review\", max_tokens=80, temperature=1.0)  # \"prefix\" 🤔\n",
        "\n",
        "text_generator = TextGenerator(vocab)\n",
        "\n",
        "EPOCHS = 5 # 🤔\n",
        "\n",
        "gpt.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[text_generator],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPJIoz9uWuZi"
      },
      "source": [
        "## Visulization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w00qy-lDWuZi"
      },
      "outputs": [],
      "source": [
        "# code to show visulization"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "GenAI_Env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "python",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
